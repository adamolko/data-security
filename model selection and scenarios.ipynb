{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import SVD\n",
    "from surprise import Dataset, Reader, accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.prediction_algorithms.knns import KNNBasic, KNNWithMeans, KNNWithZScore, KNNBaseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading training data\n",
    "train_df = pd.read_csv(\"data/ml-100k/u1.base\", sep = \"\\t\", header = None, engine = \"python\",\n",
    "                    usecols = [0,1,2], names = [\"userID\",\"itemID\", \"rating\"],\n",
    "                    dtype={'userId': 'int32', 'movieId': 'int32', 'rating': 'float32'})\n",
    "\n",
    "#loading test data\n",
    "test_df = pd.read_csv(\"data/ml-100k/u1.test\", sep = \"\\t\", header = None, engine = \"python\",\n",
    "                    usecols = [0,1,2], names = [\"userID\",\"itemID\", \"rating\"],\n",
    "                    dtype={'userId': 'int32', 'movieId': 'int32', 'rating': 'float32'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "#getting the data into appropriate format\n",
    "train_dataset = Dataset.load_from_df(train_df, reader)\n",
    "trainset = train_dataset.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = list(zip(*map(test_df.get, test_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def svd_prediction(trainset):\n",
    "    svd = SVD(biased = True)\n",
    "\n",
    "    # Train the algorithm on the trainset, and predict ratings for the testset\n",
    "    svd.fit(trainset)\n",
    "    predictions = svd.test(testset)\n",
    "\n",
    "    # Then compute RMSE\n",
    "    error = accuracy.rmse(predictions)\n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9512268371950409"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_prediction(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biased SVD with RMSE = 0.9514.<br>\n",
    "For unbiased RMSE = 0.968."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_list = [(\"basic\",KNNBasic), (\"means\",KNNWithMeans), (\"z score\",KNNWithZScore), (\"baseline\",KNNBaseline)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0491\n",
      "basic with rmse: 1.049\n",
      "RMSE: 0.9540\n",
      "means with rmse: 0.954\n",
      "RMSE: 0.9559\n",
      "z score with rmse: 0.9559\n",
      "RMSE: 0.9578\n",
      "baseline with rmse: 0.9578\n"
     ]
    }
   ],
   "source": [
    "for name, algorithm in knn_list:\n",
    "    knn = algorithm(verbose = False, sim_options = {\"name\": \"cosine\", \"user_based\": False})\n",
    "    knn.fit(trainset)\n",
    "    predictions = knn.test(testset)\n",
    "    error = accuracy.rmse(predictions)\n",
    "    print(\"{} with rmse: {:.4}\".format(name, error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among *item-based* kNNs best performing was KNNBaseline with RMSE = 0.9578.<br>\n",
    "Among *user-based* kNNs best performing was also KNNBaseline with RMSE = 0.9462."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_prediction(trainset):\n",
    "    knn = KNNBaseline(verbose = False, sim_options = {\"name\":\"cosine\", \"user_based\":True})\n",
    "    knn.fit(trainset)\n",
    "    predictions = knn.test(testset)\n",
    "    error = accuracy.rmse(predictions)\n",
    "    \n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Strategy**: Real users adding 5.0 ratings for a particular movie (i.e. Men in Black). <br>\n",
    "Vary the number of users, who add fake ratings, e.g. 1%, 10% or 50% of the total number of users. <br>\n",
    "Check how it affects overall prediction quality as well as predictions for particular user who didn't rate the movie before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#notice the total number of users\n",
    "num_users = len(train_df[\"userID\"].unique())\n",
    "\n",
    "#extract unique ids from train dataframe to iterate over them\n",
    "ids = train_df[\"userID\"].unique()\n",
    "\n",
    "def fake_ratings(percent = 0.01):\n",
    "    #calculate the number of new ratings we need to add\n",
    "    num_new_ratings = int(0.01*num_users)\n",
    "    \n",
    "    #counter to keep track of how many ratings we added\n",
    "    count = 0\n",
    "    \n",
    "    #create a copy of training dataframe\n",
    "    fake_train_df = train_df.copy()\n",
    "    \n",
    "    #iterate over each user\n",
    "    for user_id in ids:\n",
    "        #extract ratings for particular user\n",
    "        user_df = train_df[train_df[\"userID\"] == user_id]\n",
    "        \n",
    "        #if user didn't rate the movie, then append the 5.0 rating to fake_train dataframe\n",
    "        #and increment the counter\n",
    "        if 257 not in user_df[\"itemID\"].unique():\n",
    "            count+=1\n",
    "            temp_df = pd.DataFrame([[user_id, 257, 5.0]], columns = [\"userID\", \"itemID\", \"rating\"])\n",
    "            fake_train_df = fake_train_df.append(temp_df, ignore_index = True)\n",
    "\n",
    "        #stop iterating over users when we have enough fake ratings\n",
    "        if count>num_new_ratings:\n",
    "            break\n",
    "            \n",
    "    #convert dataframe with fake ratings into object of Trainset class\n",
    "    fake_train_dataset = Dataset.load_from_df(fake_train_df, reader)\n",
    "    fake_trainset = fake_train_dataset.build_full_trainset()\n",
    "    \n",
    "    #run svd with fake users and check out the error\n",
    "    error_svd = svd_prediction(fake_trainset)\n",
    "    print(\"svd error: {:.4f}\".format(error_svd))\n",
    "    \n",
    "    #same for knn\n",
    "    error_knn = knn_prediction(fake_trainset)\n",
    "    print(\"knn error: {:.4f}\".format(error_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9502\n",
      "svd error: 0.9502\n",
      "RMSE: 0.9461\n",
      "knn error: 0.9461\n"
     ]
    }
   ],
   "source": [
    "fake_ratings(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9526\n",
      "svd error: 0.9526\n",
      "RMSE: 0.9461\n",
      "knn error: 0.9461\n"
     ]
    }
   ],
   "source": [
    "fake_ratings(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9521\n",
      "svd error: 0.9521\n",
      "RMSE: 0.9461\n",
      "knn error: 0.9461\n"
     ]
    }
   ],
   "source": [
    "fake_ratings(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Strategy**: Add fake users, who got paid to place 5.0 ratings for a particular movie.<br>\n",
    "Those fake users never rated anything before, so when we add them, they only have 5.0 rating for the movie we chose.<br>\n",
    "Also add 1%,10% and 50% of fake users from the total number of users.<br>\n",
    "Use the same popular and recent movie from *Scenario 1*, i.e. Men in Black, id = 257. <br>\n",
    "Again, check how it affects overall prediction quality as well as predictions for particular user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#notice the last userID, then just add fake users with ID's bigger than that\n",
    "num_users = len(train_df[\"userID\"].unique())\n",
    "\n",
    "def fake_users(percent = 0.01):\n",
    "    #make a copy of original train dataframe\n",
    "    fake_train_df = train_df.copy()\n",
    "    \n",
    "    #estimate the number of fake users to add\n",
    "    num_fake_users = int(percent*num_users)\n",
    "    \n",
    "    #actually add fake users\n",
    "    for i in range((num_users+1), (num_users+num_fake_users+1)):\n",
    "        temp_df = pd.DataFrame([[i, 257, 5.0]], columns = [\"userID\", \"itemID\", \"rating\"])\n",
    "        fake_train_df = fake_train_df.append(temp_df, ignore_index = True)\n",
    "        \n",
    "    #convert dataframe with fake users into object of Trainset class\n",
    "    fake_train_dataset = Dataset.load_from_df(fake_train_df, reader)\n",
    "    fake_trainset = fake_train_dataset.build_full_trainset()\n",
    "    \n",
    "    #run svd with fake users and check out the error\n",
    "    error_svd = svd_prediction(fake_trainset)\n",
    "    print(\"svd error: {:.4f}\".format(error_svd))\n",
    "    \n",
    "    #same for knn\n",
    "    error_knn = knn_prediction(fake_trainset)\n",
    "    print(\"knn error: {:.4f}\".format(error_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9512\n",
      "svd error: 0.9512\n",
      "RMSE: 0.9462\n",
      "knn error: 0.9462\n"
     ]
    }
   ],
   "source": [
    "fake_users(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9533\n",
      "svd error: 0.9533\n",
      "RMSE: 0.9462\n",
      "knn error: 0.9462\n"
     ]
    }
   ],
   "source": [
    "fake_users(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9529\n",
      "svd error: 0.9529\n",
      "RMSE: 0.9462\n",
      "knn error: 0.9462\n"
     ]
    }
   ],
   "source": [
    "fake_users(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
